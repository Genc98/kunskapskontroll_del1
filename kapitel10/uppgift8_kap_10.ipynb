{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aaa840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-genai\n",
      "  Using cached google_genai-1.60.0-py3-none-any.whl.metadata (53 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from google-genai) (4.12.1)\n",
      "Collecting google-auth<3.0.0,>=2.47.0 (from google-auth[requests]<3.0.0,>=2.47.0->google-genai)\n",
      "  Downloading google_auth-2.48.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from google-genai)\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from google-genai) (9.1.2)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from google-genai) (4.15.0)\n",
      "Collecting distro<2,>=1.7.0 (from google-genai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting sniffio (from google-genai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting cryptography>=38.0.3 (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai)\n",
      "  Downloading cryptography-46.0.4-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.9.0->google-genai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3.0.0,>=2.9.0->google-genai)\n",
      "  Using cached pydantic_core-2.41.5-cp313-cp313-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.9.0->google-genai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.6.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (2.0.0)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai)\n",
      "  Using cached pyasn1-0.6.2-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\genc-\\downloads\\desktop\\skola\\11-ai-teori-och-till√§mpning-del-2\\kunskapskontroll_del1\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai) (2.23)\n",
      "Using cached google_genai-1.60.0-py3-none-any.whl (719 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading google_auth-2.48.0-py3-none-any.whl (236 kB)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading cryptography-46.0.4-cp311-abi3-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 2.1/3.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 10.1 MB/s eta 0:00:00\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached pyasn1-0.6.2-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: websockets, typing-inspection, sniffio, pydantic-core, pyasn1, distro, annotated-types, rsa, pydantic, pyasn1-modules, cryptography, google-auth, google-genai\n",
      "Successfully installed annotated-types-0.7.0 cryptography-46.0.4 distro-1.9.0 google-auth-2.48.0 google-genai-1.60.0 pyasn1-0.6.2 pyasn1-modules-0.4.2 pydantic-2.12.5 pydantic-core-2.41.5 rsa-4.9.1 sniffio-1.3.1 typing-inspection-0.4.2 websockets-15.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-6.6.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Downloading pypdf-6.6.2-py3-none-any.whl (329 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-6.6.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install google-genai\n",
    "! python -m pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd251d6",
   "metadata": {},
   "source": [
    "8. Skapa en chattbot som svarar p√• fr√•gor utifr√•n n√•got dokument som du sj√§lv v√§ljer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from pypdf import PdfReader\n",
    "api_key = '---'\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8a389",
   "metadata": {},
   "source": [
    "L√§ser in PDF-filen som √§r en gammal rapport som jag gjorde i f√∂rra AI-kursen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fea289",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"pdf/Kunskapskontroll_rapport_GencGashi.pdf\")\n",
    "\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251a7823",
   "metadata": {},
   "source": [
    "Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ecd39",
   "metadata": {},
   "source": [
    "Delar in texten i chunks s√• att modellen hanterar den enklare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679e5545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal chunks: 25.\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "n = 1000\n",
    "overlap = 200\n",
    "\n",
    "for i in range(0, len(text), n - overlap):\n",
    "    chunks.append(text[i:i + n])\n",
    "\n",
    "print(f\"Antal chunks: {len(chunks)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f4fc4",
   "metadata": {},
   "source": [
    "Jag skapar embeddings f√∂r representera texten som numeriska vektorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2793296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "def create_embeddings(text):\n",
    "    model = \"gemini-embedding-001\"\n",
    "    task_type = \"SEMANTIC_SIMILARITY\"\n",
    "    return client.models.embed_content(\n",
    "        model=model,\n",
    "        contents=text,\n",
    "        config=types.EmbedContentConfig(task_type=task_type)\n",
    "    )\n",
    "\n",
    "embeddings = create_embeddings(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f9cda",
   "metadata": {},
   "source": [
    "Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2813337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1)) * np.linalg.norm(vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d624ca24",
   "metadata": {},
   "source": [
    "G√∂r en s√∂kning igenom textchunks och returnerar mest relevanta utifr√•n likheten mellan query och chunk-embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d667fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, chunks, embeddings, k=5):\n",
    "    query_embedding = create_embeddings(query).embeddings[0].values\n",
    "    similarity_scores = []\n",
    "\n",
    "    for i, chunk_embedding in enumerate(embeddings.embeddings):\n",
    "        similarity_score = cosine_similarity(\n",
    "            query_embedding,\n",
    "            chunk_embedding.values\n",
    "        )\n",
    "        similarity_scores.append((i, similarity_score))\n",
    "\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [index for index, _ in similarity_scores[:k]]\n",
    "\n",
    "    return [chunks[index] for index in top_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27733e",
   "metadata": {},
   "source": [
    "S√∂ker efter text som √§r mest relevant till fr√•gan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9754e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tienters sjukv√•rdskostnader baserat p√• BMI, \\nk√∂n, region, √•lder, r√∂kstatus och antal barn. \\nDetta dataset valdes eftersom den passar ett regressions problem mycket v√§l. Den k√§ndes lagom \\nutmanande d√• den inte √§r extremt stor, vilket g√∂r den hanterbar. Samtidigt finns det vissa \\nsv√•righeter, till exempel att encoda de kategoriska variablerna.  En risk med datasetet √§r att det √§r \\nrelativt litet och om man rensar extremv√§rden kan det p√•verka resultaten s√• att prediktionerna blir \\nmindre korrekta. \\n \\n3.2 Tillg√•ng till data \\n \\nN√§sta steg var att l√§sa in CSV-filen i Jupyter Notebook och d√§refter h√§mta information om datasetet, \\ndess beskrivning samt de f√∂rsta raderna. D√§refter delades datan upp i tr√§nings och testdata enligt \\nfigur 4. 5 \\n \\n \\nFigur 4: Uppdelning av data. \\nTr√§ningsdatan anv√§ndes i de kommande stegen, medan testdatan sparades f√∂r att senare utv√§rdera \\nden b√§sta modellen.  \\n \\n3.3 EDA analys & Databearbetning \\n \\nEn EDA-analys utf√∂rdes p√• tr√§ningsdatan d√§r visualiseringar skapade']\n"
     ]
    }
   ],
   "source": [
    "fr√•ga = \"Vilken dataset anv√§ndes?\"\n",
    "svar = semantic_search(fr√•ga, chunks=chunks, embeddings=embeddings, k=1)\n",
    "print(svar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277a71ba",
   "metadata": {},
   "source": [
    "Generera svar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1955b55",
   "metadata": {},
   "source": [
    "Skapar en prompt som besvarar p√• fr√•gor baserat p√• PDF:en och s√§ger att den inte vet om informationen saknas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6348418",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Jag kommer st√§lla dig en fr√•ga, och jag vill att du svarar\n",
    "baserat bara p√• kontexten jag skickar med, och ingen annan information.\n",
    "Om det inte finns nog med information i kontexten f√∂r att svara p√• fr√•gan,\n",
    "s√§g \"Det vet jag inte\". F√∂rs√∂k inte att gissa.\n",
    "Formulera dig enkelt och dela upp svaret i fina stycken. \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c42a94",
   "metadata": {},
   "source": [
    "H√§r skapar jag en anv√§ndarprompt som kombinerar fr√•gan med relevant information fr√•n texten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f48eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt(query):\n",
    "    context = \"\\n\".join(semantic_search(query, chunks, embeddings))\n",
    "    user_prompt = f\"Fr√•gan √§r {query}. H√§r √§r kontexten: {context}.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f508c6",
   "metadata": {},
   "source": [
    "H√§r skickas en systemprompt och en anv√§ndares fr√•ga till modellen som sedan returnerar ett svar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2459d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(system_prompt, user_message, model=\"gemini-2.0-flash\"):\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        config=genai.types.GenerateContentConfig(\n",
    "            system_instruction=system_prompt),\n",
    "            contents=generate_user_prompt(user_message)\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "664ffeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE st√•r f√∂r Root Mean Square Error.\n",
      "\n",
      "Det visar hur bra en regressionsmodell predikterar nya v√§rden.\n",
      "\n",
      "Det ber√§knas genom att ta kvadratroten ur medelv√§rdet av de kvadrerade skillnaderna mellan de verkliga och predikterade v√§rdena.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_response(system_prompt, \"Vad √§r RMSE?\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdffea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det vet jag inte.\n"
     ]
    }
   ],
   "source": [
    "print(generate_response(system_prompt, \"Vad √§r RAG?\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5be5ba",
   "metadata": {},
   "source": [
    "Evaluering - Skriver en fr√•ga och det f√∂rv√§ntade svaret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "580ede96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vilka delar utg√∂r en RAG-modell?\n",
      "\n",
      "En RAG-modell inneh√•ller tv√• delar: \n",
      "en retriever som s√∂ker efter relevanta stycken i en text, \n",
      "och en generator som genererar svar utifr√•n den givna kontexten.\n"
     ]
    }
   ],
   "source": [
    "validation_data = [\n",
    "{\"question\": \"Vilka delar utg√∂r en RAG-modell?\",\n",
    "\"ideal_answer\": \"\"\"En RAG-modell inneh√•ller tv√• delar: \n",
    "en retriever som s√∂ker efter relevanta stycken i en text, \n",
    "och en generator som genererar svar utifr√•n den givna kontexten.\"\"\"}\n",
    "]\n",
    "\n",
    "print(validation_data[0][\"question\"])\n",
    "print()\n",
    "print(validation_data[0][\"ideal_answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4699b85",
   "metadata": {},
   "source": [
    "Det h√§r √§r en system-prompt som fungerar som ett utv√§rderingssystem. Den ger oss po√§ng (1, 0.5 eller 0) baserat p√• hur bra AI-modellens svar matchar det √∂nskade svaret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9518dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_system_prompt = \"\"\"Du √§r ett intelligent utv√§rderingssystem vars uppgift √§r att utv√§rdera en AI-assistents svar. \n",
    "Om svaret √§r v√§ldigt n√§ra det √∂nskade svaret, s√§tt po√§ngen 1. Om svaret √§r felaktigt eller inte bra nog, s√§tt po√§ngen 0.\n",
    "Om svaret √§r delvis i linje med det √∂nskade svaret, s√§tt po√§ngen 0.5. Motivera kort varf√∂r du s√§tter den po√§ng du g√∂r.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a2b6c",
   "metadata": {},
   "source": [
    "H√§r skickas fr√•gan till modellen, genererar ett svar, och skickar sedan b√•de AI-svaret och det √∂nskade svaret till modellen f√∂r utv√§rdering, och skriver sedan ut utv√§rderingsresultatet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51016183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Po√§ng: 0\n",
      "Motivering: Assistenten svarar \"Jag vet inte\" vilket inte √§r ett anv√§ndbart svar.\n"
     ]
    }
   ],
   "source": [
    "query = validation_data[0][\"question\"]\n",
    "\n",
    "response = generate_response(system_prompt, query)\n",
    "\n",
    "evaluation_prompt = f\"\"\"Fr√•ga: {query}\n",
    "AI-assistentens svar: {response.text}\n",
    "√ñnskat svar: {validation_data[0]['ideal_answer']}\"\"\"\n",
    "\n",
    "evaluation_response = generate_response(evaluation_system_prompt, evaluation_prompt)\n",
    "print(evaluation_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4464cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vilket dataset har anv√§nts?\n",
      "Medical Cost Personal\n"
     ]
    }
   ],
   "source": [
    "validation_data_2 = [\n",
    "{\"question\": \"Vilket dataset har anv√§nts?\",\n",
    "\"ideal_answer\": \"Medical Cost Personal\"}\n",
    "]\n",
    "print(validation_data_2[0][\"question\"])\n",
    "print(validation_data_2[0][\"ideal_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba96a41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasetet som har anv√§nts √§r Medical Cost Personal.\n",
      "Det best√•r av 1 338 rader och 7 kolumner:\n",
      "\n",
      "*   Age ‚Äì patientens √•lder.\n",
      "*   Sex ‚Äì patientens k√∂n (Male/Female)\n",
      "*   BMI - Body Mass Index.\n",
      "*   Smoker ‚Äì r√∂kstatus (Yes/No)\n",
      "*   Children ‚Äì antal barn som patienten har.\n",
      "*   Region ‚Äì patientens boenderegion.\n",
      "*   Charges ‚Äì patientens sjukv√•rdskostnader.\n"
     ]
    }
   ],
   "source": [
    "query = validation_data_2[0][\"question\"]\n",
    "\n",
    "response = generate_response(system_prompt, query)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "588ab62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Po√§ng: 1\n",
      "Motivering: AI-assistenten ger ett korrekt svar baserat p√• kontexten.\n"
     ]
    }
   ],
   "source": [
    "evaluation_prompt = f\"\"\"Fr√•ga: {query}\n",
    "AI-assistentens svar: {response.text}\n",
    "√ñnskat svar: {validation_data_2[0]['ideal_answer']}\"\"\"\n",
    "\n",
    "evaluation_response = generate_response(evaluation_system_prompt, evaluation_prompt)\n",
    "print(evaluation_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "518d2ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vilka modeller inom machine learning har anv√§nts?\n",
      "Linear Regression, Decision Tree och Random Forest\n"
     ]
    }
   ],
   "source": [
    "validation_data_3 = [\n",
    "{\"question\": \"Vilka modeller inom machine learning har anv√§nts?\",\n",
    "\"ideal_answer\": \"Linear Regression, Decision Tree och Random Forest\"}\n",
    "]\n",
    "print(validation_data_3[0][\"question\"])\n",
    "print(validation_data_3[0][\"ideal_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4a3ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F√∂ljande modeller inom machine learning har anv√§nts:\n",
      "\n",
      "*   Linj√§r regression.\n",
      "*   Random Forest.\n",
      "*   Decision Tree.\n"
     ]
    }
   ],
   "source": [
    "query = validation_data_3[0][\"question\"]\n",
    "\n",
    "response = generate_response(system_prompt, query)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8526b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Po√§ng: 1\n",
      "Motivering: Svaret inneh√•ller samtliga modeller som har anv√§nts.\n"
     ]
    }
   ],
   "source": [
    "evaluation_prompt = f\"\"\"Fr√•ga: {query}\n",
    "AI-assistentens svar: {response.text}\n",
    "√ñnskat svar: {validation_data_3[0]['ideal_answer']}\"\"\"\n",
    "\n",
    "evaluation_response = generate_response(evaluation_system_prompt, evaluation_prompt)\n",
    "print(evaluation_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b384e0",
   "metadata": {},
   "source": [
    "En enkel applikation som √§r en chattbot som kan svara p√• fr√•gor om min kunskapskontroll fr√•n f√∂rra kursen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb1b0104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot\n",
      "\n",
      "Fr√•ga: vilket dataset anv√§ndes?\n",
      "\n",
      "AI-svar: Datasetet som anv√§ndes var \"Medical Cost Personal\". \n",
      "\n",
      "\n",
      "Fr√•ga: ber√§tta om rymden\n",
      "\n",
      "AI-svar: Det vet jag inte. \n",
      "\n",
      "\n",
      "Fr√•ga: Vad √§r RMSE?\n",
      "\n",
      "AI-svar: RMSE visar hur bra en regressionsmodell predikterar nya v√§rden.\n",
      "\n",
      "Det ber√§knas genom att ta kvadratroten ur medelv√§rdet av de kvadrerade skillnaderna mellan de verkliga och predikterade v√§rdena.\n",
      "\n",
      "Formeln f√∂r RMSE √§r:\n",
      "\n",
      "`ùëÖùëÄùëÜùê∏ = ‚àö1/ùëõ ‚àë (ùë¶ùëñ  ‚àí  ùë¶ÃÇ1)^2ùëõ\n",
      "ùëñ=0`\n",
      "\n",
      "H√§r √§r:\n",
      "*   ùë¶ùëñ de verkliga v√§rdena,\n",
      "*   ùë¶ÃÇ1 motsvarar de predikterade v√§rdena\n",
      "*   n √§r antalet observationer. \n",
      "\n",
      "\n",
      "Fr√•ga: Vad √§r CNN?\n",
      "\n",
      "AI-svar: Det vet jag inte. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot\")\n",
    "\n",
    "while True:\n",
    "    fr√•ga = input(\"\")\n",
    "    if fr√•ga.lower() == \"q\":\n",
    "        break\n",
    "    \n",
    "    print(\"\\nFr√•ga:\", fr√•ga)\n",
    "    svar = generate_response(system_prompt, fr√•ga)\n",
    "    print(\"\\nAI-svar:\", svar.text, \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kunskapskontroll-koduppgifter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
